{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **BONUS TASK**\n",
        "\n",
        "\n",
        "This problem description is the same as Task 3. But there are some\n",
        "technical challenges that you have to choose one.\n",
        "\n",
        "1. Compare 3 different configurations while your model is\n",
        "wider/deeper. Show and explain the performance result.\n",
        "2. Compare 3 configurations for different Loss Function. Show and\n",
        "explain your performance result.\n",
        "\n",
        "3. Compare 3 configurations for the activation function. Show and\n",
        "explain your performance result."
      ],
      "metadata": {
        "id": "bRohs-Uvp0h4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "z7j6c9cIpt_D"
      },
      "outputs": [],
      "source": [
        "# Import Library yang dibutuhkan\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan transformasi data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Muat dataset MNIST\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Muat data loader\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "PwLP3nHiqJb8"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk melatih model\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')"
      ],
      "metadata": {
        "id": "FI4rPlVNqNqE"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk mengevaluasi model\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    confusion = confusion_matrix(all_labels, all_predictions)\n",
        "    class_rep = classification_report(all_labels, all_predictions)\n",
        "\n",
        "    return accuracy, confusion, class_rep"
      ],
      "metadata": {
        "id": "eJrwgLLNqUEK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1. Compare 3 different configurations while your model is wider/deeper. Show and explain the performance result.***"
      ],
      "metadata": {
        "id": "pAdu3bPbqZyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Konfigurasi Model 1 (Lebar dan Dalam)\n",
        "class Model1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model1, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "j6nRxlG0qYqK"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konfigurasi Model 2 (Lebih Lebar)\n",
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model2, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nXYCfnhTqjv7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konfigurasi Model 3 (Lebih Dalam)\n",
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model3, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GzjYvle2qwfW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pelatihan dan Evaluasi Model 1\n",
        "model1 = Model1()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "train_model(model1, train_loader, criterion, optimizer, num_epochs)\n",
        "accuracy1, _, class_rep1 = evaluate_model(model1, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW0O9ojtq0Nm",
        "outputId": "badfe893-a9cc-4e7f-a328-6e878f259ee2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.40519687937679827\n",
            "Epoch 2/10, Loss: 0.20259827782890436\n",
            "Epoch 3/10, Loss: 0.14584674270970543\n",
            "Epoch 4/10, Loss: 0.11981882021001884\n",
            "Epoch 5/10, Loss: 0.09721967279970614\n",
            "Epoch 6/10, Loss: 0.08480274702793658\n",
            "Epoch 7/10, Loss: 0.07785453742145618\n",
            "Epoch 8/10, Loss: 0.06922205952184796\n",
            "Epoch 9/10, Loss: 0.06323463225941747\n",
            "Epoch 10/10, Loss: 0.054849735868008516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pelatihan dan Evaluasi Model 2\n",
        "model2 = Model2()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "train_model(model2, train_loader, criterion, optimizer, num_epochs)\n",
        "accuracy2, _, class_rep2 = evaluate_model(model2, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBy0rQY6q-4U",
        "outputId": "c21f0b09-4736-49a7-8f14-3aa7f7d1d87f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.34442666483554507\n",
            "Epoch 2/10, Loss: 0.15307433876409524\n",
            "Epoch 3/10, Loss: 0.111466390741016\n",
            "Epoch 4/10, Loss: 0.09126874967974656\n",
            "Epoch 5/10, Loss: 0.07473855895468834\n",
            "Epoch 6/10, Loss: 0.06633453107568553\n",
            "Epoch 7/10, Loss: 0.0591479428954284\n",
            "Epoch 8/10, Loss: 0.05392558632906514\n",
            "Epoch 9/10, Loss: 0.04639040173325779\n",
            "Epoch 10/10, Loss: 0.043696730310888665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pelatihan dan Evaluasi Model 3\n",
        "model3 = Model3()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model3.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "train_model(model3, train_loader, criterion, optimizer, num_epochs)\n",
        "accuracy3, _, class_rep3 = evaluate_model(model3, test_loader)"
      ],
      "metadata": {
        "id": "DR9BkTaRttcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93e79b0-b5b4-4e4b-ede7-e52b9e88a36f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.3745742074644832\n",
            "Epoch 2/10, Loss: 0.17127199743840613\n",
            "Epoch 3/10, Loss: 0.12842342012258037\n",
            "Epoch 4/10, Loss: 0.10488218935092351\n",
            "Epoch 5/10, Loss: 0.08865011812819204\n",
            "Epoch 6/10, Loss: 0.07705588576330273\n",
            "Epoch 7/10, Loss: 0.06791769566936796\n",
            "Epoch 8/10, Loss: 0.06515849332761035\n",
            "Epoch 9/10, Loss: 0.05761375319699683\n",
            "Epoch 10/10, Loss: 0.052888454128793234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EVALUASI MODEL"
      ],
      "metadata": {
        "id": "tUSKHUHMwTu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Fungsi untuk mengevaluasi model\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    confusion = confusion_matrix(all_labels, all_predictions)\n",
        "    class_rep = classification_report(all_labels, all_predictions)\n",
        "\n",
        "    return accuracy, confusion, class_rep\n",
        "\n",
        "# Evaluasi Model 1\n",
        "accuracy1, confusion1, class_rep1 = evaluate_model(model1, test_loader)\n",
        "\n",
        "# Evaluasi Model 2\n",
        "accuracy2, confusion2, class_rep2 = evaluate_model(model2, test_loader)\n",
        "\n",
        "# Evaluasi Model 3\n",
        "accuracy3, confusion3, class_rep3 = evaluate_model(model3, test_loader)"
      ],
      "metadata": {
        "id": "6yWl4GTowWfD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 1**"
      ],
      "metadata": {
        "id": "uZP7F6f3wqwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cetak hasil evaluasi untuk masing-masing model\n",
        "print(\"Model 1 Evaluation:\")\n",
        "print(\"\\n\")\n",
        "print(f'Accuracy: {accuracy1:.4f}')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion1)\n",
        "print('Classification Report:')\n",
        "print(class_rep1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wu3UW4VwhW7",
        "outputId": "2153da3b-f76b-4ed7-8e72-cb616876d5ac"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 Evaluation:\n",
            "\n",
            "\n",
            "Accuracy: 0.9698\n",
            "Confusion Matrix:\n",
            "[[ 974    0    1    0    0    0    3    1    1    0]\n",
            " [   0 1122    1    4    0    1    0    4    1    2]\n",
            " [  12    2 1006    1    2    0    1    7    1    0]\n",
            " [   3    0    2  990    0    5    0    6    3    1]\n",
            " [   6    0    3    2  931    0    5    6    0   29]\n",
            " [   7    1    0   15    1  852    8    1    2    5]\n",
            " [  13    6    3    1    3    3  926    0    3    0]\n",
            " [   1    0    5    5    0    0    0 1008    1    8]\n",
            " [  14    0    5   18    6    7    6    5  904    9]\n",
            " [   6    1    0    6    4    3    0    4    0  985]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.98      0.97      0.98      1032\n",
            "           3       0.95      0.98      0.96      1010\n",
            "           4       0.98      0.95      0.97       982\n",
            "           5       0.98      0.96      0.97       892\n",
            "           6       0.98      0.97      0.97       958\n",
            "           7       0.97      0.98      0.97      1028\n",
            "           8       0.99      0.93      0.96       974\n",
            "           9       0.95      0.98      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 2**"
      ],
      "metadata": {
        "id": "hcV5UvdXwwM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model 2 Evaluation:\")\n",
        "print(\"\\n\")\n",
        "print(f'Accuracy: {accuracy2:.4f}')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion2)\n",
        "print('Classification Report:')\n",
        "print(class_rep2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPiVbTHMwknx",
        "outputId": "9ad37453-fb0e-4741-d2e0-82a7ee9acfdd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 Evaluation:\n",
            "\n",
            "\n",
            "Accuracy: 0.9756\n",
            "Confusion Matrix:\n",
            "[[ 973    0    1    0    0    0    1    1    3    1]\n",
            " [   0 1126    0    2    0    1    3    1    2    0]\n",
            " [   6    2  995    9    3    0    2    8    7    0]\n",
            " [   2    0    1  990    0    1    0    7    6    3]\n",
            " [   2    0    2    0  957    1    3    3    0   14]\n",
            " [   4    1    0   17    4  838    6    2   12    8]\n",
            " [   6    2    0    0    7    5  938    0    0    0]\n",
            " [   1    3    6    0    2    0    0 1000    1   15]\n",
            " [   7    0    1    2    3    1    2    5  947    6]\n",
            " [   2    1    0    3    4    2    1    4    0  992]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.99      0.96      0.98      1032\n",
            "           3       0.97      0.98      0.97      1010\n",
            "           4       0.98      0.97      0.98       982\n",
            "           5       0.99      0.94      0.96       892\n",
            "           6       0.98      0.98      0.98       958\n",
            "           7       0.97      0.97      0.97      1028\n",
            "           8       0.97      0.97      0.97       974\n",
            "           9       0.95      0.98      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 3**"
      ],
      "metadata": {
        "id": "QegYRLiww2d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model 3 Evaluation:\")\n",
        "print(\"\\n\")\n",
        "print(f'Accuracy: {accuracy3:.4f}')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion3)\n",
        "print('Classification Report:')\n",
        "print(class_rep3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDldzY8cwyI0",
        "outputId": "e6fac7f0-fb46-4c64-8251-5155e5d6e341"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 Evaluation:\n",
            "\n",
            "\n",
            "Accuracy: 0.9715\n",
            "Confusion Matrix:\n",
            "[[ 941    0    2    2    1   12    7    5    4    6]\n",
            " [   0 1126    0    2    0    2    1    1    3    0]\n",
            " [   1    2 1004    8    5    3    2    2    5    0]\n",
            " [   0    0    2  991    0    4    0    6    3    4]\n",
            " [   2    0    1    0  948    6    3    3    0   19]\n",
            " [   1    0    0   16    0  865    2    1    4    3]\n",
            " [   1    3    0    1    6   15  929    0    3    0]\n",
            " [   0    4    6   11    1    1    0 1001    0    4]\n",
            " [   1    0    1   14    0    5    1    3  944    5]\n",
            " [   1    2    0   12    5    7    0   10    6  966]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.99      0.97      0.98      1032\n",
            "           3       0.94      0.98      0.96      1010\n",
            "           4       0.98      0.97      0.97       982\n",
            "           5       0.94      0.97      0.95       892\n",
            "           6       0.98      0.97      0.98       958\n",
            "           7       0.97      0.97      0.97      1028\n",
            "           8       0.97      0.97      0.97       974\n",
            "           9       0.96      0.96      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PENJELASAN**\n",
        "<br>\n",
        "\n",
        "***Model 1 (Lebar dan Dalam)***\n",
        "- Terdiri dari tiga layer linear (fully connected) dengan 128, 64, dan 10 neuron berturut-turut.\n",
        "- Total layer 4 (termasuk input)\n",
        "- Arsitektur: 28x28 (input) -> 128 -> 64 -> 10 (output).\n",
        "- Model ini mencapai akurasi yang baik yaitu sekitar 96.98% pada dataset MNIST.\n",
        "\n",
        "***Model 2 (Lebih lebar)***\n",
        "- Terdiri dari tiga layer linear (fully connected) dengan 256, 128, dan 10 neuron berturut-turut.\n",
        "- Total layer 4 (termasuk input)\n",
        "- Arsitektur: 28x28 (input) -> 256 -> 128 -> 10 (output).\n",
        "- Model ini mencapai akurasi yang lebih tinggi yaitu sekitar 97.56% dibandingkan dg Model 1.\n",
        "\n",
        "***Model 3 (Lebih dalam)***\n",
        "- Terdiri dari empat layer linear (fully connected) dengan 128 neuron pada setiap layer.\n",
        "- Total layer 5 (termasuk input).\n",
        "- Arsitektur: 28x28 (input) -> 128 -> 128 -> 128 -> 10 (output).\n",
        "- Model ini mencapai akurasi yang lebih rendah dari Model ke 2 yaitu sekitar 97.15% tetapi memiliki akurasi lebih tinggi dari Model ke 1.\n",
        "\n",
        "\n",
        "**KESIMPULAN**\n",
        "- Model 2 (Lebih Lebar) memiliki potensi untuk menangani fitur lebih kompleks karena memiliki lebih banyak neuron pada layer pertama.\n",
        "- Model 3 (Lebih Dalam) memiliki kedalaman yang lebih besar dengan lebih banyak layer yg dapat membantu dalam memahami representasi data yg lebih kompleks.\n",
        "- Model 1 (Lebar dan Dalam) adalah model yang berada di tengah-tengah dalam hal kedalaman dan lebar.\n",
        "\n",
        "\n",
        "Jadi, dari interpretasi di atas,  Model 2 adalah pilihan terbaik karena memiliki akurasi tertinggi dan kinerja yang baik secara keseluruhan dalam mengklasifikasikan data MNIST.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BL2AxjHr1Wup"
      }
    }
  ]
}